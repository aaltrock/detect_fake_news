/Users/aaronaltrock/PycharmProjects/detect_fake_news_data_flow_bs/venv/bin/python /Users/aaronaltrock/PycharmProjects/detect_fake_news_data_flow_bs/01_gcp_bucket_to_bigquery_dataflow.py --source_bucket_name src_fake_news_bs --source_bucket_base_path to_add --input gs://src_fake_news_bs/to_add/*.parquet --processed_bucket_success added --processed_bucket_error gs://src_fake_news_bs/error --runner DataflowRunner --project fake-news-bs-detector --bigquery_output_dataset fake_news --bigquery_output_table src_fake_news --staging_location gs://fake_news_cleaned_json/staging --temp_location gs://src_fake_news_python_bs/tmp/ --template_location gs://src_fake_news_python_bs/template1 --requirements_file ./requirements_01_gcp_bucket_to_bigquery_dataflow.txt --json_key_path ./fake-news-bs-detector-62e838f6b99c.json --runner DirectRunner
Arguments:
Namespace(bigquery_output_dataset='fake_news', bigquery_output_table='src_fake_news', input='gs://src_fake_news_bs/to_add/*.parquet', json_key_path='./fake-news-bs-detector-62e838f6b99c.json', processed_bucket_error='gs://src_fake_news_bs/error', processed_bucket_success='added', project='fake-news-bs-detector', runner='DirectRunner', source_bucket_base_path='to_add', source_bucket_name='src_fake_news_bs', temp_location='gs://src_fake_news_python_bs/tmp/')
Started at: 2021-10-25 00:35:34.252638
Started at: 2021-10-25 00:35:34.254596
Downloaded storage object template.yml from bucket src_fake_news_bs to local file template.yml.
INFO:root:Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.
INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.
INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.
INFO:apache_beam.io.gcp.gcsio:Starting the size estimation of the input
INFO:oauth2client.transport:Attempting refresh to obtain initial access_token
INFO:oauth2client.client:Refreshing access_token
INFO:apache_beam.io.gcp.gcsio:Finished listing 3 files in 0.32311296463012695 seconds.
WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.
INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.33.0
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function annotate_downstream_side_inputs at 0x7f9d89e7e9e0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function fix_side_input_pcoll_coders at 0x7f9d89e7eb00> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function pack_combiners at 0x7f9d89e7ef80> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function lift_combiners at 0x7f9d89e7c050> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_sdf at 0x7f9d89e7c200> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_gbk at 0x7f9d89e7c290> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sink_flattens at 0x7f9d89e7c3b0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function greedily_fuse at 0x7f9d89e7c440> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function read_to_impulse at 0x7f9d89e7c4d0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function impulse_to_input at 0x7f9d89e7c560> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sort_stages at 0x7f9d89e7c7a0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function setup_timer_mapping at 0x7f9d89e7c710> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function populate_data_channel_coders at 0x7f9d89e7c830> ====================
INFO:apache_beam.runners.worker.statecache:Creating state cache with size 100
INFO:apache_beam.runners.portability.fn_api_runner.worker_handlers:Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f9d89f55c10> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')
INFO:apache_beam.runners.portability.fn_api_runner.fn_runner:Running ((((ref_AppliedPTransform_Read-copied-csv-file-Read-Impulse_4)+(ref_AppliedPTransform_Read-copied-csv-file-Read-Map-lambda-at-iobase-py-898-_5))+(Read copied .csv file/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/PairWithRestriction))+(Read copied .csv file/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction))+(ref_PCollection_PCollection_2_split/Write)
INFO:apache_beam.io.gcp.gcsio:Starting the size estimation of the input
INFO:apache_beam.io.gcp.gcsio:Finished listing 3 files in 0.08728408813476562 seconds.
INFO:apache_beam.io.gcp.gcsio:Starting the size estimation of the input
INFO:apache_beam.io.gcp.gcsio:Finished listing 3 files in 0.08057403564453125 seconds.
INFO:apache_beam.runners.portability.fn_api_runner.fn_runner:Running ((((ref_PCollection_PCollection_2_split/Read)+(Read copied .csv file/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process))+(ref_AppliedPTransform_Read-copied-csv-file-ParDo-_ArrowTableToRowDictionaries-_8))+(ref_AppliedPTransform_Parse-records_9))+(ref_PCollection_PCollection_5/Write)
INFO:apache_beam.runners.portability.fn_api_runner.fn_runner:Running ((((ref_AppliedPTransform_PCollection-to-Pandas-Data-Frame-Impulse_11)+(ref_AppliedPTransform_PCollection-to-Pandas-Data-Frame-FlatMap-lambda-at-core-py-2968-_12))+(ref_AppliedPTransform_PCollection-to-Pandas-Data-Frame-Map-decode-_14))+(ref_AppliedPTransform_As-Pandas_15))+(ref_AppliedPTransform_Write-to-GCP-BigQuery_16)
12953 out of 12953 rows loaded.
1it [00:24, 24.38s/it]
WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.
INFO:root:Default Python SDK image for environment is apache/beam_python3.7_sdk:2.33.0
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function annotate_downstream_side_inputs at 0x7f9d89e7e9e0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function fix_side_input_pcoll_coders at 0x7f9d89e7eb00> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function pack_combiners at 0x7f9d89e7ef80> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function lift_combiners at 0x7f9d89e7c050> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_sdf at 0x7f9d89e7c200> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_gbk at 0x7f9d89e7c290> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sink_flattens at 0x7f9d89e7c3b0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function greedily_fuse at 0x7f9d89e7c440> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function read_to_impulse at 0x7f9d89e7c4d0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function impulse_to_input at 0x7f9d89e7c560> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sort_stages at 0x7f9d89e7c7a0> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function setup_timer_mapping at 0x7f9d89e7c710> ====================
INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function populate_data_channel_coders at 0x7f9d89e7c830> ====================
INFO:apache_beam.runners.worker.statecache:Creating state cache with size 100
INFO:apache_beam.runners.portability.fn_api_runner.worker_handlers:Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7f9d89f98dd0> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')
INFO:apache_beam.runners.portability.fn_api_runner.fn_runner:Running ((((ref_AppliedPTransform_Read-copied-csv-file-Read-Impulse_4)+(ref_AppliedPTransform_Read-copied-csv-file-Read-Map-lambda-at-iobase-py-898-_5))+(Read copied .csv file/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/PairWithRestriction))+(Read copied .csv file/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitAndSizeRestriction))+(ref_PCollection_PCollection_2_split/Write)
INFO:apache_beam.io.gcp.gcsio:Starting the size estimation of the input
INFO:apache_beam.io.gcp.gcsio:Finished listing 3 files in 0.10781717300415039 seconds.
INFO:apache_beam.io.gcp.gcsio:Starting the size estimation of the input
INFO:apache_beam.io.gcp.gcsio:Finished listing 3 files in 0.11657500267028809 seconds.
INFO:apache_beam.runners.portability.fn_api_runner.fn_runner:Running ((((ref_PCollection_PCollection_2_split/Read)+(Read copied .csv file/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process))+(ref_AppliedPTransform_Read-copied-csv-file-ParDo-_ArrowTableToRowDictionaries-_8))+(ref_AppliedPTransform_Parse-records_9))+(ref_PCollection_PCollection_5/Write)
INFO:apache_beam.runners.portability.fn_api_runner.fn_runner:Running ((((ref_AppliedPTransform_PCollection-to-Pandas-Data-Frame-Impulse_11)+(ref_AppliedPTransform_PCollection-to-Pandas-Data-Frame-FlatMap-lambda-at-core-py-2968-_12))+(ref_AppliedPTransform_PCollection-to-Pandas-Data-Frame-Map-decode-_14))+(ref_AppliedPTransform_As-Pandas_15))+(ref_AppliedPTransform_Write-to-GCP-BigQuery_16)
12953 out of 12953 rows loaded.
1it [00:29, 29.68s/it]
Blob to_add/risdal.parquet in bucket src_fake_news_bs moved to blob added/risdal.parquet in bucket src_fake_news_bs.
Blob to_add/risdal.parquet.yml in bucket src_fake_news_bs moved to blob added/risdal.parquet.yml in bucket src_fake_news_bs.
Completed at: 2021-10-25 00:38:43.391208
Duration: 0:03:09.136612
END

Process finished with exit code 0